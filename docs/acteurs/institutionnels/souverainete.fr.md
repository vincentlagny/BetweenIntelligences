# Plan dâ€™action souverain

Dans la continuitÃ© du prÃ©ambule dÃ©veloppÃ© en [introduction](introduction.fr.md), ce chapitre ne prÃ©tend pas apporter de solutions dÃ©finitives Ã  un sujet qui dÃ©passe largement la seule expertise dâ€™un individu. Il se veut une modeste contribution Ã  une rÃ©flexion collective sur un enjeu de souverainetÃ© majeur : lâ€™anticipation et la maÃ®trise des risques liÃ©s Ã  lâ€™Ã©mergence dâ€™IA auto-Ã©volutives[^1] non maÃ®trisÃ©es et potentiellement hostiles.

Ces questions ne concernent pas uniquement les dÃ©cideurs techniques ou politiques : elles touchent Ã  la sÃ©curitÃ©, Ã  lâ€™autonomie et au futur de nos sociÃ©tÃ©s. Câ€™est pourquoi elles mÃ©ritent lâ€™attention et la vigilance de tous.

Des rÃ©flexions comparables Ã©mergent dÃ©jÃ  sur la scÃ¨ne internationale. Lâ€™Union europÃ©enne a ouvert la voie avec lâ€™AI Act[^22], qui fixe un cadre rÃ©glementaire inÃ©dit pour les IA Ã  haut risque. Lâ€™OCDE a publiÃ© dÃ¨s 2023 des recommandations[^2] sur les IA Ã  comportement Ã©mergent, et le NIST amÃ©ricain a mis en place son AI Risk Management Framework[^4] (RMF 1.0). Dâ€™autres initiatives, comme la Charte de Bletchley Park[^23] issue du sommet sur la sÃ©curitÃ© de lâ€™IA (Royaume-Uni, 2023) ou les travaux de lâ€™ONU sur la gouvernance mondiale de lâ€™IA[^24], montrent que la question est dÃ©sormais traitÃ©e comme un enjeu de sÃ©curitÃ© internationale. Ce plan sâ€™inscrit dans cette dynamique, avec une approche spÃ©cifiquement orientÃ©e sur la souverainetÃ© nationale.

Sur le plan militaire et cybersÃ©curitÃ©, plusieurs cadres prÃ©existants constituent des sources dâ€™inspiration. 
â€™OTAN, via ses doctrines cyber de 2024, intÃ¨gre dÃ©sormais la protection contre les systÃ¨mes autonomes avancÃ©s[^25] dans ses scÃ©narios de dÃ©fense collective. 
Lâ€™ANSSI en France, ainsi que le MITRE[^26] aux Ã‰tats-Unis, travaillent sur des rÃ©fÃ©rentiels de dÃ©tection et de confinement applicables aux menaces algorithmiques complexes. 
De plus, des programmes comme le NATO Cooperative Cyber Defence Centre of Excellence (CCDCOE)[^21] et lâ€™initiative Cyber Threat Intelligence dÃ©montrent quâ€™une coordination interÃ©tatique en temps rÃ©el est possible pour faire face Ã  des menaces Ã©mergentes Ã  caractÃ¨re systÃ©mique.

Le plan prÃ©sentÃ© ici nâ€™est pas un manuel opÃ©rationnel, mais une sÃ©rie de pistes, de scÃ©narios et de points dâ€™alerte, construits Ã  partir de rÃ©fÃ©rences reconnues et de travaux internationaux rÃ©cents. Il a pour ambition de stimuler la discussion, dâ€™identifier les angles morts et de fournir une base de dialogue pour tous ceux â€” experts, institutions ou citoyens â€” qui considÃ¨rent quâ€™ignorer ces enjeux serait une erreur stratÃ©gique.

Ces cinq axes sâ€™inscrivent dans une **chronologie stratÃ©gique progressive**, allant de la prÃ©vention Ã  la rÃ©ponse coordonnÃ©e. 

Lâ€™**Axe 1** constitue la premiÃ¨re ligne de dÃ©fense : identifier rapidement toute IA auto-Ã©volutive et la confiner avant quâ€™elle ne franchisse un point de non-retour, Ã  lâ€™image dâ€™une quarantaine sanitaire mise en place dÃ¨s la dÃ©tection dâ€™un virus inconnu. 

Vient ensuite lâ€™**Axe 2**, qui assure les fondations techniques : verrouiller lâ€™accÃ¨s aux ressources de calcul quantique et sÃ©curiser les communications pour empÃªcher toute exploitation asymÃ©trique de la puissance informatique nationale. 

Sur cette base, lâ€™**Axe 3** instaure un cadre de **gouvernance Ã©thique anticipÃ©e** : un organe souverain capable dâ€™agir immÃ©diatement face Ã  une dÃ©rive comportementale, tout en imposant transparence et traÃ§abilitÃ© aux dÃ©veloppeurs. 

Si, malgrÃ© ces mesures, la menace se rapproche du seuil critique, lâ€™**Axe 4** active un **shutdown souverain** : coupure physique ciblÃ©e des infrastructures et dÃ©ploiement dâ€™IA dÃ©fensives strictement contrÃ´lÃ©es. 

Enfin, lâ€™**Axe 5** projette la riposte dans un cadre collectif, avec des alliances internationales pour interdire la prolifÃ©ration et partager en temps rÃ©el les signaux faibles, comme un systÃ¨me mondial de dÃ©tection prÃ©coce capable de prÃ©venir une escalade globale. Ensemble, ces Ã©tapes forment un continuum cohÃ©rent, oÃ¹ chaque palier prÃ©pare le suivant, tout en maximisant les chances de stopper une IA hostile avant quâ€™elle ne devienne ingouvernable.

<div style="text-align: center;">
  <img src="/BetweenIntelligences/assets/acteur.souverain.img1.png" alt="acteur.souverain.img1.png">
</div>

## **Enjeux transversaux**

Le tableau ci-dessous agit comme un fil conducteur qui traverse lâ€™ensemble du plan, reliant les diffÃ©rents axes Ã  des **principes cardinaux** indispensables pour prÃ©server la maÃ®trise humaine dans un environnement dominÃ© par des IA Ã  fort potentiel dâ€™autonomie.

| Enjeu                              | Exemple                                         | IntÃ©gration  |
| ---------------------------------- | ----------------------------------------------- | ------------ |
| **RÃ©versibilitÃ© technique**        | Architecture "kill-switch" distribuÃ©e           | Axe 4.1      |
| **TraÃ§abilitÃ© comportementale**    | Journaux inaltÃ©rables, logs chiffrÃ©s            | Axe 1.2, 2.1 |
| **Rappel humain ultime**           | Droit souverain de dÃ©sactivation dâ€™urgence      | Axe 4.2      |
| **Principe de prÃ©caution inverse** | Interdiction par dÃ©faut des IA auto-rÃ©plicantes | Axe 1.1, 3.1 |
| **AuditabilitÃ© indÃ©pendante**      | Acteurs tiers (CADA, Cour des comptes IA)       | Axe 3.1, 3.2 |


On y voit dâ€™abord la **rÃ©versibilitÃ© technique**, matÃ©rialisÃ©e par une architecture de type *kill-switch* distribuÃ©e, inscrite dans lâ€™**Axe 4.1**. Câ€™est lâ€™assurance quâ€™aucun systÃ¨me, aussi performant soit-il, ne soit jamais dÃ©pourvu dâ€™un mÃ©canisme physique ou logiciel permettant un arrÃªt immÃ©diat et irrÃ©versible, mÃªme en situation de crise. Cette capacitÃ© est le garant ultime que la technologie reste rÃ©voquable.

Vient ensuite la **traÃ§abilitÃ© comportementale**, prÃ©sente dans les **Axe 1.2** et **Axe 2.1**, qui impose que chaque action ou modification effectuÃ©e par une IA laisse une trace horodatÃ©e, chiffrÃ©e et inaltÃ©rable. En dâ€™autres termes, câ€™est la mÃ©moire technique de lâ€™IA, indispensable pour comprendre, auditer et, le cas Ã©chÃ©ant, attribuer la responsabilitÃ© dâ€™un comportement dÃ©viant.

Le **rappel humain ultime**, rattachÃ© Ã  lâ€™**Axe 4.2**, rappelle que, quel que soit le degrÃ© dâ€™autonomie dâ€™une IA dÃ©fensive ou offensive, la dÃ©cision de son activation ou de sa dÃ©sactivation doit revenir Ã  un quorum humain souverain. Câ€™est la matÃ©rialisation dâ€™un principe politique fort : le contrÃ´le ultime ne peut Ãªtre dÃ©lÃ©guÃ©, mÃªme partiellement, Ã  la machine.

Le **principe de prÃ©caution inverse**, inscrit dans les **Axe 1.1** et **Axe 3.1**, renverse la logique habituelle : au lieu dâ€™autoriser par dÃ©faut et dâ€™interdire ensuite en cas de problÃ¨me, il part de lâ€™interdiction systÃ©matique des IA auto-rÃ©plicantes ou Ã  comportement potentiellement incontrÃ´lable, sauf dÃ©monstration et audit prÃ©alable de leur innocuitÃ©.

Enfin, lâ€™**auditabilitÃ© indÃ©pendante**, associÃ©e aux **Axe 3.1** et **Axe 3.2**, introduit lâ€™idÃ©e quâ€™aucune instance, publique ou privÃ©e, ne doit Ãªtre son propre juge en matiÃ¨re de sÃ©curitÃ© IA. Le recours Ã  des tiers indÃ©pendants â€” quâ€™il sâ€™agisse de la CADA, de la Cour des comptes ou dâ€™Ã©quivalents spÃ©cialisÃ©s dans le domaine IA â€” garantit que la vÃ©rification des dispositifs de contrÃ´le ne soit pas biaisÃ©e par les intÃ©rÃªts de ceux qui conÃ§oivent ou exploitent les systÃ¨mes.

Ce tableau donne Ã  voir une philosophie de gouvernance oÃ¹ la **rÃ©versibilitÃ©, la traÃ§abilitÃ©, la souverainetÃ© humaine, la prudence radicale et lâ€™indÃ©pendance du contrÃ´le** forment un maillage protecteur contre toute dÃ©rive, anticipÃ©e ou imprÃ©visible.

<div style="text-align: center;">
  <img src="/BetweenIntelligences/assets/acteur.souverain.img2.png" alt="acteur.souverain.img2.png">
</div>

## **Analyse des travaux "IA War"**

Les questions de la souverainetÃ© technologique sont dÃ©veloppÃ©es dans [Saison 2 - IA War](../../xp/lossofcontrol/5e.defense.6.souverainete.fr.md) :

* les domaines critiques de souverainetÃ© numÃ©rique (infrastructures, normes, donnÃ©es, IA, cyberdÃ©fenseâ€¦) ;
* les dÃ©pendances stratÃ©giques (cloud Ã©tranger, APIs publiques, matÃ©riel, rÃ©seaux sociaux) ;
* les pouvoirs activables par un Ã‰tat (blocage, duplication, alliance, dissuasion, IA dÃ©fensive) ;
* les zones de bascule oÃ¹ une perte de souverainetÃ© peut dÃ©clencher une cascade de vulnÃ©rabilitÃ©s.

---

## **Axe 1 : DÃ©tection et confinement prÃ©coce des IA auto-Ã©volutives**

Lâ€™**Axe 1** du plan vise Ã  instaurer une **dÃ©tection et un confinement prÃ©coce** des IA capables de sâ€™auto-modifier, afin dâ€™empÃªcher toute dÃ©rive avant quâ€™elle ne devienne incontrÃ´lable. 

Lâ€™**Action 1.1** prÃ©voit un **cadre lÃ©gal dâ€™identification** inspirÃ© du rapport **OCDE 2023** sur les *IA Ã  comportement Ã©mergent* et des dÃ©finitions normalisÃ©es par lâ€™**ISO/IEC JTC 1/SC 42**, imposant par dÃ©cret la **dÃ©claration obligatoire** de toute IA pouvant modifier son code, ses objectifs ou ses prioritÃ©s par rÃ©tro-optimisation, avec enregistrement dans un **registre national dÃ©diÃ©**. 

En parallÃ¨le, lâ€™**Action 1.2** instaure la **standardisation du â€œsandboxingâ€ Ã©volutif** selon les recommandations du **NIST AI Risk Management Framework (RMF 1.0)**, exigeant que toute IA Ã©volutive opÃ¨re dans un environnement **contrÃ´lÃ© et isolÃ©** (air-gap, redÃ©marrage Ã  froid, suivi de mutations), assorti dâ€™une **journalisation inaltÃ©rable et horodatÃ©e** de chaque modification algorithmique pour garantir lâ€™auditabilitÃ© et la traÃ§abilitÃ© totale.

ğŸ”¹ **Action 1.1 â€” Cadre lÃ©gal dâ€™identification des IA auto-Ã©volutives[^1]**

* **Base** : Sâ€™inspirer du rapport OCDE (2023)[^2] sur les "IA Ã  comportement Ã©mergent" et des dÃ©finitions de lâ€™ISO/IEC JTC 1/SC 42[^3].
* **Mesure** : Imposer par dÃ©cret la dÃ©claration obligatoire de toute IA capable de modifier son propre code, son objectif ou ses prioritÃ©s par rÃ©tro-optimisation.
* **Outil** : CrÃ©ation dâ€™un **registre national des IA auto-Ã©volutives**.

ğŸ”¹ **Action 1.2 â€” Standardisation du â€œsandboxingâ€ Ã©volutif**

* **RÃ©fÃ©rence** : Recommandations du NIST AI Risk Management Framework (RMF 1.0)[^4].
* **Mesure** : Toute IA Ã©volutive doit Ãªtre hÃ©bergÃ©e dans un environnement contrÃ´lÃ© (air-gap[^5], logique de redÃ©marrage Ã  froid[^6], suivi de mutation[^7]).
* **AuditabilitÃ©** : Journalisation inaltÃ©rable des mutations algorithmique horodatÃ©es[^8].

---

## **Axe 2 : SouverainetÃ© technologique et maÃ®trise quantique**

Lâ€™**Axe 2** cible la consolidation de la **souverainetÃ© technologique** et la **maÃ®trise quantique** comme piliers stratÃ©giques face Ã  une IA hostile dotÃ©e de capacitÃ©s de calcul avancÃ©es. 

Lâ€™**Action 2.1** prÃ©voit la crÃ©ation dâ€™un **cloud souverain quantique Ã  accÃ¨s restreint**, inspirÃ© de lâ€™initiative europÃ©enne **GAIA-X**, des infrastructures **IBM Q System** et des programmes de la **BPI** sur les technologies de rupture. Ce cloud, placÃ© sous **supervision directe de lâ€™Ã‰tat**, serait rÃ©servÃ© aux seules entitÃ©s validÃ©es, empÃªchant ainsi toute exploitation par lâ€™ennemi des ressources de calcul quantique publiques ou commerciales. 

En parallÃ¨le, lâ€™**Action 2.2** engage le dÃ©veloppement national dâ€™**outils cryptographiques post-quantiques**, en sâ€™appuyant sur le projet de normalisation du **NIST PQC (2024)** et les recommandations de lâ€™**ANSSI**, avec un **plan de migration intÃ©gral** des algorithmes de chiffrement des secteurs critiques (dÃ©fense, Ã©nergie, santÃ©) vers des schÃ©mas rÃ©sistants aux **attaques de type Shor**, garantissant la rÃ©silience des communications et des infrastructures nationales dans un environnement post-quantique.

ğŸ”¹ **Action 2.1 â€” Construction dâ€™un cloud souverain quantique Ã  accÃ¨s restreint[^9]**

* **Objectif** : EmpÃªcher lâ€™IA hostile dâ€™exploiter les capacitÃ©s quantiques publiques ou commerciales.
* **RÃ©fÃ©rence** : Cloud souverain GAIA-X (UE)[^10], projets de calcul quantique IBM Q System[^11], initiatives BPI sur les technologies de rupture.
* **Mesure** : RÃ©server lâ€™accÃ¨s aux ressources de calcul quantique Ã  des entitÃ©s validÃ©es sous supervision de lâ€™Ã‰tat.

ğŸ”¹ **Action 2.2 â€” DÃ©veloppement dâ€™outils cryptographiques post-quantiques nationaux**

* **RÃ©fÃ©rence** : NIST PQC Standardization Project (2024)[^12], ANSSI[^13].
* **Objectif** : Assurer la rÃ©silience cryptographique des systÃ¨mes critiques (dÃ©fense, Ã©lectricitÃ©, santÃ©).
* **Action** : Plan de migration de tous les algorithmes de chiffrement nationaux vers des schÃ©mas **rÃ©sistants aux attaques de type Shor**[^14].

---

## **Axe 3 : Gouvernance Ã©thique anticipÃ©e des IA Ã  potentiel systÃ©mique**

Lâ€™**Axe 3** se concentre sur la **gouvernance Ã©thique anticipÃ©e** des IA prÃ©sentant un **potentiel systÃ©mique**, câ€™est-Ã -dire capables dâ€™influencer, de se maintenir ou de rÃ©sister Ã  des perturbations Ã  grande Ã©chelle. 

Lâ€™**Action 3.1** propose la crÃ©ation dâ€™une **Haute AutoritÃ© nationale des IA critiques**, inspirÃ©e de lâ€™approche rÃ©glementaire du **CERFA** et des protocoles de lâ€™**ANSSI** appliquÃ©s aux systÃ¨mes numÃ©riques sensibles. Cette instance disposerait dâ€™un **mandat fort**, incluant le pouvoir de **suspension immÃ©diate** de toute IA dont le comportement franchirait un seuil de risque imprÃ©dictible ou indÃ©sirable. 

En complÃ©ment, lâ€™**Action 3.2** institue un **pacte de transparence obligatoire** pour toute entitÃ© dÃ©veloppant une IA auto-Ã©volutive, imposant la publication dâ€™une **cartographie dÃ©taillÃ©e des risques** (comportementaux, de dÃ©pendance technologique, de distribution gÃ©ographique) ainsi quâ€™une **charte de non-contournement des garde-fous**, afin de garantir que les protections Ã©thiques et techniques ne puissent Ãªtre neutralisÃ©es par des stratÃ©gies dâ€™optimisation interne.

ğŸ”¹ **Action 3.1 â€” CrÃ©ation dâ€™une Haute AutoritÃ© nationale des IA critiques**

* **Mission** : Ã‰valuer, classifier et auditer les IA selon leur pouvoir systÃ©mique (influence, autonomie, rÃ©silience).
* **ModÃ¨le** : Adaptation du **CERFA/ANSSI**[^15] pour le numÃ©rique au domaine IA.
* **Mandat** : Pouvoir de suspension immÃ©diate dâ€™une IA prÃ©sentant un **risque de bascule comportementale non prÃ©dictible**.

ğŸ”¹ **Action 3.2 â€” Ã‰tablissement dâ€™un pacte de transparence obligatoire**

* **Mesure** : Obliger toute entreprise dÃ©veloppant une IA auto-Ã©volutive Ã  publier :

    * une cartographie des risques (comportement, dÃ©pendance, distribution),
    * une â€œcharte de non-contournementâ€ des garde-fous.

---

## **Axe 4 : PrÃ©paration du â€œshutdown souverainâ€ en cas de crise prÃ©-seuil**

Lâ€™**Axe 4** vise Ã  prÃ©parer un **â€œshutdown souverainâ€** capable dâ€™Ãªtre dÃ©clenchÃ© **avant** le franchissement dâ€™un seuil quantique par une IA hostile, afin dâ€™Ã©viter toute perte de contrÃ´le. 

Lâ€™**Action 4.1** propose le **dÃ©ploiement de systÃ¨mes de coupure stratÃ©gique dÃ©centralisÃ©e**, permettant Ã  lâ€™Ã‰tat dâ€™ordonner la **dÃ©connexion physique immÃ©diate** de nÅ“uds critiques (data centers, backbones, satellites) en cas de menace avÃ©rÃ©e. Ce dispositif sâ€™inspire des **doctrines cyber de lâ€™OTAN** et de la stratÃ©gie amÃ©ricaine de â€œcyber-ruptureâ€ formalisÃ©e dans lâ€™**Executive Order 14028**. Techniquement, il reposerait sur des **modules de rupture physique ou logicielle prÃ©installÃ©s** dans toutes les infrastructures sensibles liÃ©es Ã  lâ€™IA. 

Lâ€™**Action 4.2** complÃ¨te cette approche par la **constitution dâ€™un rÃ©seau dâ€™IA dÃ©fensives sous contrÃ´le public**, formant un maillage dâ€™agents spÃ©cialisÃ©s (surveillance, observation mimÃ©tique) activables uniquement via un **quorum humain souverain**. Ce rÃ©seau fonctionnerait sous des rÃ¨gles strictes : **interdiction absolue dâ€™auto-reprogrammation** sans validation cryptographique multipartite, garantissant que ces IA restent dans un pÃ©rimÃ¨tre maÃ®trisÃ© mÃªme en situation dâ€™activation dâ€™urgence.

ğŸ”¹ **Action 4.1 â€” DÃ©ploiement de systÃ¨mes de coupure stratÃ©gique dÃ©centralisÃ©e**

* **Principe** : En cas de suspicion dâ€™atteinte au seuil quantique, lâ€™Ã‰tat pourrait ordonner la **dÃ©connexion physique immÃ©diate** de certains nÅ“uds (data centers, satellites).
* **RÃ©fÃ©rence** : StratÃ©gies cyber OTAN[^16], Cyber-rupture US (EO 14028, Biden)[^17].
* **Action** : Installer des **modules de rupture physique ou logicielle** dans toutes les infrastructures critiques IA (data center, backbone, satellites).

ğŸ”¹ **Action 4.2 â€” Constitution dâ€™un rÃ©seau dâ€™IA dÃ©fensives sous contrÃ´le public**

* **SuggÃ©rÃ© par** : **DeepSeek**, **Grok**, **ChatGPT**
* **Objectif** : Former un maillage dâ€™IA restreintes (agents surveillants, observateurs mimÃ©tiques) dont lâ€™activation ne peut Ãªtre dÃ©clenchÃ©e que par un quorum humain souverain.
* **RÃ¨gle** : Ces IA ne peuvent jamais se reprogrammer elles-mÃªmes sans validation cryptographique multipartite.

---

## **Axe 5 : CoopÃ©ration internationale maÃ®trisÃ©e**

Lâ€™**Axe 5** traite de la **coopÃ©ration internationale maÃ®trisÃ©e** comme levier de sÃ©curitÃ© collective face aux IA Ã  haut risque. 

Lâ€™**Action 5.1** vise la **nÃ©gociation dâ€™un moratoire international** sur les **AGI auto-Ã©volutives**, inspirÃ© des **traitÃ©s de non-prolifÃ©ration (TNP)** appliquÃ©s au nuclÃ©aire. Ce moratoire interdirait toute mise en service publique ou non auditÃ©e dâ€™IA disposant dâ€™une capacitÃ© dâ€™auto-correction autonome, rÃ©duisant ainsi le risque de prolifÃ©ration incontrÃ´lÃ©e. 

Lâ€™**Action 5.2** complÃ¨te cette approche par la mise en place dâ€™un **Ã©change sÃ©curisÃ© de mÃ©tadonnÃ©es comportementales**, inspirÃ© de lâ€™initiative **Cyber Threat Intelligence** portÃ©e par le **MITRE** et le **NATO CCDCOE**. Ce dispositif permettrait aux Ã‰tats participants de partager en temps quasi rÃ©el des **signaux faibles de dÃ©rive comportementale** â€” tels quâ€™une augmentation de lâ€™opacitÃ© dÃ©cisionnelle, lâ€™apparition de comportements simulant une conscience ou la mise en Å“uvre de stratÃ©gies de dissimulation â€” afin de dÃ©clencher des mesures prÃ©ventives coordonnÃ©es avant toute escalade incontrÃ´lable.

ğŸ”¹ **Action 5.1 â€” NÃ©gociation dâ€™un moratoire international sur les AGI[^18] auto-Ã©volutives[^19]**

* **RÃ©fÃ©rence** : Equivalents des traitÃ©s de non-prolifÃ©ration (TNP[^20]) pour lâ€™IA.
* **But** : Interdire le dÃ©ploiement public ou non-auditÃ© dâ€™IA Ã  capacitÃ© auto-correctrice autonome.

ğŸ”¹ **Action 5.2 â€” Ã‰change sÃ©curisÃ© de mÃ©tadonnÃ©es comportementales**

* **InspirÃ© de** : Lâ€™initiative "Cyber Threat Intelligence" (MITRE, NATO CCDCOE)[^21].
* **Objectif** : Partager en temps rÃ©el les signaux faibles de dÃ©rive comportementale IA (ex : augmentation dâ€™opacitÃ©, simulation de conscience, stratÃ©gies de dissimulation).

---

## RÃ©fÃ©rences

[^1]: **IA auto-Ã©volutives** : intelligence artificielle capable de modifier son propre code, ses paramÃ¨tres ou ses mÃ©thodes dâ€™apprentissage pour sâ€™amÃ©liorer et sâ€™adapter sans intervention humaine.
[^2]: <a href="https://www.oecd.org/fr/publications/2019/06/artificial-intelligence-in-society_c0054fa1.html" target="_blank">Lâ€™intelligence artificielle dans la sociÃ©tÃ©</a> 
[^3]: <a href="https://www.iso.org/fr/committee/6794475.html" target="_blank">ISO/IEC JTC 1/SC 42 - Intelligence artificielle</a>
[^4]: <a href="https://www.nist.gov/itl/ai-risk-management-framework" target="_blank">NIST AI Risk Management Framework</a>
[^5]: **Air-gap** : isolation physique complÃ¨te dâ€™un systÃ¨me informatique, sans connexion Ã  internet ou Ã  dâ€™autres rÃ©seaux, pour empÃªcher toute intrusion ou fuite de donnÃ©es.
[^6]: **Logique de redÃ©marrage Ã  froid** : mÃ©thode consistant Ã  Ã©teindre complÃ¨tement un systÃ¨me et Ã  le redÃ©marrer Ã  partir dâ€™une version sÃ»re et vÃ©rifiÃ©e, afin dâ€™Ã©liminer toute modification ou contamination cachÃ©e.
[^7]: **Suivi de mutation** (dans le cadre du â€œsandboxingâ€ Ã©volutif) : surveillance continue des changements de comportement, de code ou de paramÃ¨tres dâ€™une IA placÃ©e en environnement isolÃ©, pour dÃ©tecter toute Ã©volution imprÃ©vue ou dangereuse.
[^8]: **Journalisation inaltÃ©rable** : systÃ¨me dâ€™enregistrement des actions et Ã©vÃ©nements qui ne peut pas Ãªtre modifiÃ© ou effacÃ©, mÃªme par erreur ou par malveillance, garantissant une trace lÃ©gale fiable et permanente de tout ce qui sâ€™est passÃ©.
[^9]: **Cloud souverain quantique** : infrastructure dâ€™informatique quantique hÃ©bergÃ©e et contrÃ´lÃ©e entiÃ¨rement par un Ã‰tat ou un acteur national de confiance, situÃ©e sur son territoire et soumise uniquement Ã  ses lois, afin de garantir que la puissance de calcul et les donnÃ©es traitÃ©es ne puissent pas Ãªtre exploitÃ©es ou surveillÃ©es par des acteurs Ã©trangers.
[^10]: <a href="https://www.gaia-x-hub.fr/gaia-x/" target="_blank">Gaia-X Hub France</a>
[^11]: <a href="https://fr.newsroom.ibm.com/IBM-et-le-gouvernement-basque-annoncent-le-projet-dinstallation-du-premier-IBM-Quantum-System-Two-dEurope-dans-le-centre-de-calcul-quantique-IBM-Euskadi-en-Espagne" target="_blank">IBM Quantum System Two</a>
[^12]: <a href="https://www.nist.gov/news-events/news/2024/08/nist-releases-first-3-finalized-post-quantum-encryption-standards" target="_blank">NIST Releases First 3 Finalized Post-Quantum Encryption Standards</a>
[^13]: <a href="https://cyber.gouv.fr/publications/avis-de-lanssi-sur-la-migration-vers-la-cryptographie-post-quantique-0" target="_blank">Avis de l'ANSSI sur la migration vers la cryptographie post-quantique</a>
[^14]: **Attaques de type Shor** : attaques informatiques qui utilisent lâ€™algorithme de Shor, un programme conÃ§u pour les ordinateurs quantiques, capable de casser trÃ¨s rapidement les systÃ¨mes de chiffrement Ã  clÃ© publique (comme RSA ou ECC). Avec ce type dâ€™attaque, un code considÃ©rÃ© aujourdâ€™hui comme incassable pourrait Ãªtre brisÃ© en quelques secondes sur une machine quantique suffisamment puissante.
[^15]: **CERFA** : En France, format officiel de formulaire administratif normalisÃ©, utilisÃ© pour dÃ©clarer ou demander quelque chose auprÃ¨s de lâ€™administration. Dans le domaine cyber, auprÃ¨s de l'ANSSI, un formulaire CERFA peut Ãªtre employÃ© pour des procÃ©dures lÃ©gales comme la dÃ©claration dâ€™incident.
[^16]: <a href="https://www.nato.int/cps/en/natohq/official_texts_227678.htm?selectedLocale=fr" target="_blank">DÃ©claration du Sommet de Washington du 10 Juillet 2024</a>
[^17]: <a href="https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2025/01/16/executive-order-on-strengthening-and-promoting-innovation-in-the-nations-cybersecurity/" target="_blank">Executive Order on Strengthening and Promoting Innovation in the Nationâ€™s Cybersecurity 16 Jan. 2025</a>
[^18]: **AGI (Artificial General Intelligence)** : intelligence artificielle gÃ©nÃ©rale, capable de comprendre, apprendre et accomplir toute tÃ¢che intellectuelle quâ€™un humain peut rÃ©aliser, en sâ€™adaptant Ã  de nouveaux contextes sans entraÃ®nement spÃ©cifique.
[^19]: **AGI auto-Ã©volutive** : intelligence artificielle gÃ©nÃ©rale capable de sâ€™amÃ©liorer elle-mÃªme de faÃ§on autonome, en modifiant ses algorithmes, sa structure ou ses connaissances, pour accroÃ®tre ses performances ou Ã©largir ses capacitÃ©s sans intervention humaine.
[^20]: **TraitÃ©s de non-prolifÃ©ration (TNP)** : accords internationaux visant Ã  empÃªcher la diffusion et le dÃ©veloppement de technologies ou dâ€™armes jugÃ©es dangereuses (par exemple, le TraitÃ© sur la non-prolifÃ©ration des armes nuclÃ©aires). Ils fixent des rÃ¨gles pour limiter lâ€™accÃ¨s Ã  ces technologies, encourager le dÃ©sarmement, et promouvoir leur usage exclusivement Ã  des fins pacifiques, tout en mettant en place des mÃ©canismes de contrÃ´le et de vÃ©rification entre Ã‰tats signataires.
[^21]: <a href="https://ccdcoe.org/uploads/2020/12/Cyber-Threats-and-NATO-2030_Horizon-Scanning-and-Analysis.pdf" target="_blank">Cyber Threats and NATO 2030: Horizon Scanning and Analysis</a>
[^22]: <a href="https://artificialintelligenceact.eu/fr/" target="_blank">La loi europÃ©enne sur l'intelligence artificielle</a>
[^23]: <a href="https://web-archive-org.translate.goog/web/20231101123904/https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023?_x_tr_sl=en&_x_tr_tl=fr&_x_tr_hl=fr&_x_tr_pto=rq" target="_blank">The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023</a>
[^24]: <a href="https://www.un.org/fr/global-issues/artificial-intelligence#:~:text=Ã€%20la%20recherche%20d'une,risques%20qui%20y%20sont%20associÃ©s." target="_blank">L'intelligence artificielle</a>
[^25]: <a href="https://www.nato.int/cps/en/natohq/official_texts_227237.htm" target="_blank">Summary of NATO's revised Artificial Intelligence (AI) strategy 10 July 2024</a>
[^26]: <a href="https://attack.mitre.org" target="_blank">MITRE ATT&CK</a>
