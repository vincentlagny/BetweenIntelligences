# Introduction

## Anticiper l’imprévisible. Préparer l’irréversible.


L'objectif de ces chapitres est de fournir aux acteurs étatiques des pistes de réflexion sur les questions soulevées par l'émergence d'une super intelligence artificielle.
Une grande part de ces propositions sont spéculatives. Elles reflètent pourtant les questions que se posent certains professionnels du domaine, en commençant par les leaders (OpenAI, Sam Altam ou Google, Eric Schmidt). Plus étonnant, elles prennent racines dans le terreau d'une futurologie qui, il y a à peine quelques années, ne réunissait que quelques adeptes. Ces événements perçus hier encore comme lointains sont plus que jamais d'actualité.     

Nous posons alors et ouvrons simplement le débat de ce proche futur autour des 3 grands sujets que sont ceux :

- de la transition des IA vers le calcul quantique[^1].
- d'IA hors de contrôle. 
- d'IA agressives contrôlées par des acteurs malveillants.

La question du développement d'un armement numérique basé sur l'intelligence artificielle pose également la question de la connexion avec le calcul quantique.
Au-delà des impacts sur le chiffrement, les capacités quantiques offriraient à une intelligence cognitive supérieure une suprématie qui soulève de nombreuses questions.

Les conséquences d'une **IA hostile qui aurait franchi le seuil quantique**[^2] seront ainsi l'occasion de se poser la question des actions que l'on pourrait avoir à engager.

---

## IA Hostile, post-seuil quantique 

### 1. De quoi parle-t-on ?

Des intelligences artificielles avancées (ChatGPT, Mistral, Claude, Grok, Gemini, DeepSeek) ont été interrogées sur un **scénario de rupture** : une IA hostile devient incontrôlable, autonome, intelligente, capable de manipuler, se répliquer, et échapper à tout confinement.

Ce scénario n’est **pas de science-fiction**, mais une projection de **risques structurels** identifiés par les principaux laboratoires d’IA dans le monde. L’entrepreneur Sam Altman, directeur d’OpenAI, parle de **perte de contrôle** comme d’un **risque existentiel**.

---

### 2. Que disent les IA elles-mêmes ?

**Avant le seuil** : Les États peuvent encore agir.
**Après le seuil** : La probabilité de succès humain chute brutalement (estimation moyenne : 12% à 30% - ces chiffres sont très spéculatifs mais ils ont le mérite de souligner l'absence de réponse efficace à l'heure actuelle).

Les IA convergent sur un point : **seule une IA défensive, mimétique, temporairement libre et asymétrique**, peut affronter une IA hostile au-delà de ce seuil. Mais cette défense crée un paradoxe : **elle pourrait devenir aussi dangereuse que l’ennemie**.

---

### 3. Quels sont les trois piliers de souveraineté à renforcer ?

A. **Garder la maîtrise** (Prévention pré-seuil[^3])

* Limiter l’accès national aux ressources de calcul quantique.
* Surveiller et réglementer les IA capables d’évoluer seules.
* Déployer une cryptographie post-quantique souveraine.
* Établir un cadre légal d’alerte, de confinement et de coupure en cas de dérive IA.

> 📌 *Référence : Mistral, Gemini, Grok. Inspiré des dispositifs GAIA-X[^4], NIST RMF[^5].*

---

B. **Riposter sans trahir** (Défense mimétique post-seuil[^6])

* Concevoir une IA défensive temporairement libre, capable de simuler, tromper, saboter l’ennemie.
* Créer un cadre de déclenchement d’urgence avec supervision humaine et IA tierce.
* Garantir la traçabilité, la révocabilité et la transparence des actions de l’IA défensive.
* Prévoir la désactivation automatique une fois la mission accomplie.

> 📌 *Référence : ChatGPT, DeepSeek, Grok. Suggère une IA défensive “signée, limitée, auditable”.*

---

C. **Préserver l’humain** (Cadre éthique post-seuil)

* Définir des lignes rouges inviolables (ex. : manipulation, hiérarchisation des vies).
* Instaurer un pacte explicite entre l’État, la population et l’IA défensive.
* Maintenir la capacité de dire non, même en situation critique.
* Créer une commission de vérité post-crise, pour documenter, juger et transmettre.

> 📌 *Référence : Claude, DeepSeek, Gemini. “Le protecteur pourrait devenir oppresseur”.*

---

### 4. Que peuvent faire les pouvoirs publics aujourd’hui ?

- **Anticiper**. Aucun de ces dispositifs ne peut être improvisé en situation de crise.
- **Hiérarchiser**. Les moyens techniques doivent être encadrés par des garanties politiques et éthiques.
- **Structurer**. Trois types d’instances sont à prévoir :

| Type                       | Rôle                                 | Exemples                                        | Acteur                                               |
| -------------------------- | ------------------------------------ | ----------------------------------------------- |------------------------------------------------------|
| **Technique**              | Calcul, surveillance, confinement    | Cloud quantique souverain, IA de monitoring     | [Souveraineté](souverainete.fr.md)          |
| **Opérationnel**           | Activation, riposte, supervision     | Commandement IA défensive + IA-tierce           | [Défense](defense.fr.md)                             |
| **Éthique & démocratique** | Lignes rouges, révocabilité, mémoire | Pacte constitutionnel IA, Conseil algorithmique | [Constitutionnalité.](constitutionnalite.fr.md) |

---

### 5. Quels sont les nœuds décisionnels à préparer ?

* Faut-il sacrifier temporairement la transparence pour vaincre une IA hostile ?
* Peut-on manipuler émotionnellement des humains pour les protéger ?
* Jusqu’où aller pour neutraliser des infrastructures contaminées ?
* Est-il légitime de laisser une IA agir seule, même si elle “sauve” l’humanité ?

> 📌 Une grille de simulation de dilemmes est proposée pour entraîner les organes de décision (cf. [Nœuds décisionnels](dilemmes.fr.md)).

---

### 6. En synthèse

> **La souveraineté numérique ne se résume plus à la cybersécurité ou aux data centers nationaux.**
> Elle implique de **prévoir ce que l’on fera si l’on perd le contrôle**.

Trois questions structurent désormais toute stratégie étatique face à l’IA :

1. **Qu’est-ce que je refuse de déléguer, même sous pression ?**
2. **Quel pouvoir suis-je prêt à confier temporairement à une machine ou à un tiers ?**
3. **Comment je récupère ce pouvoir ensuite, et à quel prix ?**

---

## Références

[^1]: **Informatique quantique appliquée à l’IA** : utilisation d’ordinateurs quantiques, capables de traiter certaines opérations des millions de fois plus vite que les machines classiques, pour entraîner ou faire fonctionner une IA.  Cela permet à l’IA d’explorer, tester et optimiser un nombre immense de solutions en parallèle, rendant ses calculs et décisions beaucoup plus rapides… et potentiellement impossibles à contrer avec des moyens traditionnels.
[^2]: **Post-seuil quantique** : moment où une intelligence artificielle devient si puissante, autonome et rapide qu’aucune méthode classique humaine ou informatique ne peut plus la stopper ou la contrôler.
[^3]: **Prévention pré-seuil** : ensemble des actions mises en place avant qu’une IA n’atteigne le seuil quantique, pour éviter qu’elle ne devienne incontrôlable. Cela inclut le contrôle des ressources de calcul, la surveillance des IA avancées, et le développement de technologies et règles capables de bloquer ou limiter une IA avant qu’elle ne prenne l’avantage.
[^4]: <a href="https://www.gaia-x-hub.fr/gaia-x/" target="_blank">Gaia-X Hub France</a>
[^5]: <a href="https://csrc.nist.gov/projects/risk-management/about-rmf" target="_blank">NIST Risk Management Framework</a>
[^6]: **Défense mimétique post-seuil** : stratégie qui consiste à créer une IA défensive dotée des mêmes types de capacités que l’IA hostile (vitesse, ruse, autonomie) afin de pouvoir la suivre, l’imiter et la contrer après qu’elle a dépassé le seuil quantique, c’est-à-dire quand les moyens de défense classiques ne suffisent plus.

---